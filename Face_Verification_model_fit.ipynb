{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Verification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smgTeuy3iW3D",
        "colab_type": "text"
      },
      "source": [
        "## Notebook for face verification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqynvVKKhQeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GGMHNAkivPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c15c60b5-17e6-403b-b4b6-6a3fa8b4333e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as K\n",
        "import os\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "print(tf.__version__)\n",
        "print(K.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipFXBapciWZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Connect with drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNcQ-Q2Likkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read data from drive\n",
        "with open('drive/My Drive/Face Verification/haarcascade_frontalface_default.xml', 'r') as f:\n",
        "    haar_file = f.read()\n",
        "\n",
        "print(haar_file)\n",
        "#with open('drive/My Drive/Smart Reply/10000_labels.csv', 'r') as f:\n",
        "    #labels = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZGxznt9oR6P",
        "colab_type": "text"
      },
      "source": [
        "# Take 20 photos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oK-3Cf_no8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5ecbd495-6721-4b9d-9307-46d2224b752e"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "# All the faces data will be present this folder \n",
        "dataset = './dataset'\n",
        "\n",
        "if not os.path.exists(dataset):\n",
        "    os.mkdir(dataset)\n",
        "sub_data = input(\"Enter your username: \")\n",
        "#sub_data_gray = input(\"Enter your username for gray scale: \")\n",
        "\n",
        "# Use the username as path name\n",
        "path = os.path.join(dataset, sub_data) \n",
        "path_gray = 'dataset/{}{}'.format(sub_data,'_gray')\n",
        "\n",
        "# Add a verfication for this step\n",
        "if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "    os.mkdir(path_gray)    \n",
        "\n",
        "def take_photo(filename='dataset/name/photo.jpg', quality=1):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your username: george\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19cfCmUqno7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "ed24ead9-c7aa-41db-eafb-bfccde7bf50f"
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# Take 20 photos\n",
        "for i in range(20):\n",
        "  try:\n",
        "    filename = take_photo(filename='dataset/{}/photo{}.jpg'.format(sub_data,i))\n",
        "    print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "    #display(Image(filename))\n",
        "  except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "    print(str(err))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo0.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo1.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo2.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo3.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo4.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo5.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo6.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo7.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo8.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo9.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo10.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo11.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo12.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo13.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo14.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo15.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo16.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo17.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo18.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo19.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKN_wBnTWRx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# zip saved model folder\n",
        "!zip -r /content/dataset/george.zip /content/dataset/george"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KshBKGWFYo4U",
        "colab_type": "text"
      },
      "source": [
        "## If you come later unzip the file with photos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQT-J7X-Ysb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14c7a9e1-4590-44de-f47b-55586cb125c2"
      },
      "source": [
        "if not os.path.exists('dataset'):\n",
        "    os.mkdir('dataset')\n",
        "\n",
        "if not os.path.exists('dataset_gray'):\n",
        "    os.mkdir('dataset_gray')\n",
        "\n",
        "!unzip george.zip -d dataset\n",
        "!unzip Kim.zip -d dataset\n",
        "!unzip Bean.zip -d dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  george.zip\n",
            "   creating: dataset/george/\n",
            "  inflating: dataset/george/photo0.jpg  \n",
            "  inflating: dataset/george/photo1.jpg  \n",
            "  inflating: dataset/george/photo10.jpg  \n",
            "  inflating: dataset/george/photo11.jpg  \n",
            "  inflating: dataset/george/photo12.jpg  \n",
            "  inflating: dataset/george/photo13.jpg  \n",
            "  inflating: dataset/george/photo14.jpg  \n",
            "  inflating: dataset/george/photo15.jpg  \n",
            "  inflating: dataset/george/photo16.jpg  \n",
            "  inflating: dataset/george/photo17.jpg  \n",
            "  inflating: dataset/george/photo18.jpg  \n",
            "  inflating: dataset/george/photo19.jpg  \n",
            "  inflating: dataset/george/photo2.jpg  \n",
            "  inflating: dataset/george/photo3.jpg  \n",
            "  inflating: dataset/george/photo4.jpg  \n",
            "  inflating: dataset/george/photo5.jpg  \n",
            "  inflating: dataset/george/photo6.jpg  \n",
            "  inflating: dataset/george/photo7.jpg  \n",
            "  inflating: dataset/george/photo8.jpg  \n",
            "  inflating: dataset/george/photo9.jpg  \n",
            "Archive:  Kim.zip\n",
            "   creating: dataset/Kim/\n",
            "  inflating: dataset/Kim/001.jpg     \n",
            "  inflating: dataset/Kim/002.jpg     \n",
            "  inflating: dataset/Kim/003.jpg     \n",
            "  inflating: dataset/Kim/004.jpg     \n",
            "  inflating: dataset/Kim/005.jpg     \n",
            "  inflating: dataset/Kim/006.jpg     \n",
            "  inflating: dataset/Kim/007.jpg     \n",
            "  inflating: dataset/Kim/008.jpg     \n",
            "  inflating: dataset/Kim/009.jpg     \n",
            "  inflating: dataset/Kim/011.jpg     \n",
            "  inflating: dataset/Kim/012.jpg     \n",
            "  inflating: dataset/Kim/014.jpg     \n",
            "  inflating: dataset/Kim/015.jpg     \n",
            "  inflating: dataset/Kim/016.jpg     \n",
            "  inflating: dataset/Kim/017.jpg     \n",
            "  inflating: dataset/Kim/018.jpg     \n",
            "  inflating: dataset/Kim/020.jpg     \n",
            "  inflating: dataset/Kim/021.jpg     \n",
            "  inflating: dataset/Kim/023.jpg     \n",
            "  inflating: dataset/Kim/027.jpg     \n",
            "Archive:  Bean.zip\n",
            "   creating: dataset/Bean/\n",
            "  inflating: dataset/Bean/001.jpg    \n",
            "  inflating: dataset/Bean/002.jpg    \n",
            "  inflating: dataset/Bean/003.jpg    \n",
            "  inflating: dataset/Bean/004.jpg    \n",
            "  inflating: dataset/Bean/005.jpg    \n",
            "  inflating: dataset/Bean/006.jpg    \n",
            "  inflating: dataset/Bean/007.jpg    \n",
            "  inflating: dataset/Bean/008.jpg    \n",
            "  inflating: dataset/Bean/009.jpg    \n",
            "  inflating: dataset/Bean/010.jpg    \n",
            "  inflating: dataset/Bean/011.jpg    \n",
            "  inflating: dataset/Bean/012.jpg    \n",
            "  inflating: dataset/Bean/013.jpg    \n",
            "  inflating: dataset/Bean/014.jpg    \n",
            "  inflating: dataset/Bean/015.jpg    \n",
            "  inflating: dataset/Bean/016.jpg    \n",
            "  inflating: dataset/Bean/017.jpg    \n",
            "  inflating: dataset/Bean/018.jpg    \n",
            "  inflating: dataset/Bean/019.jpg    \n",
            "  inflating: dataset/Bean/020.jpg    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8QnMJVjjfp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "path_gray_george = 'dataset_gray/{}'.format('george')\n",
        "\n",
        "# Add a verfication for this step\n",
        "if not os.path.exists(path_gray_george):\n",
        "    os.mkdir(path_gray_george) \n",
        "\n",
        "sub_data = 'george'\n",
        "\n",
        "def create_dataset_george():\n",
        "    # The file containing the pretrained classifier \n",
        "    haar_file = 'drive/My Drive/Face Verification/haarcascade_frontalface_default.xml'\n",
        "        \n",
        "    # Image to be resized to this shape\n",
        "    (width, height) = (180, 200)     \n",
        "    \n",
        "    # Make the cascade classifier object\n",
        "    face_cascade = cv2.CascadeClassifier(haar_file) \n",
        "    #webcam = cv2.VideoCapture(0)  \n",
        "\n",
        "    # The program loops until it has 20 images of the face. \n",
        "    count = 0\n",
        "    while count < 20:\n",
        "        # Read from file\n",
        "        # Creates blueish file\n",
        "        im = PIL.Image.open('dataset/{}/photo{}.jpg'.format(sub_data,count))\n",
        "        # Creates images with normal color\n",
        "        #im = cv2.imread('dataset/{}/photo{}.jpg'.format(sub_data,count))\n",
        "        im = np.array(im)\n",
        "        #print(im.shape)\n",
        "        \n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) \n",
        "        # Detect the face\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 4) \n",
        "        \n",
        "        face_resize = None\n",
        "        for (x, y, w, h) in faces:\n",
        "            # The classifier seemed to scrap the chin and hair. Adjustments made to accomodate those.\n",
        "            face = im[y-60 : y+h+60, x-20 : x+w+20] \n",
        "            face_resize = cv2.resize(face, (width, height)) \n",
        "            cv2.imwrite('% s/% s.png' % (path_gray_george, 'photoGeorge{}'.format(count)), face_resize) \n",
        "        count += 1\n",
        "\n",
        "        #cv2.imshow('OpenCV', im) \n",
        "        #key = cv2.waitKey(100) \n",
        "        #if key == 27: \n",
        "            #break\n",
        "\n",
        "# Call this function whenever you need to create a dataset of the person's images\n",
        "create_dataset_george()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ez0dU9Lr1kf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9dfd3c85-f037-41a3-9aea-7bd88b357b1f"
      },
      "source": [
        "\n",
        "path_gray_Bean = 'dataset_gray/{}'.format('Bean')\n",
        "\n",
        "# Add a verfication for this step\n",
        "if not os.path.exists(path_gray_Bean):\n",
        "    os.mkdir(path_gray_Bean) \n",
        "\n",
        "sub_data = 'Bean'\n",
        "dir_contents_Bean = os.listdir('dataset/Bean')\n",
        "print(len(dir_contents_Bean))\n",
        "\n",
        "def create_dataset_Bean():\n",
        "   \n",
        "    # Image to be resized to this shape\n",
        "    (width, height) = (180, 200) \n",
        "\n",
        "    # The program loops until it has 20 images of the face. \n",
        "    count = 0\n",
        "    while count < 20:\n",
        "        # Read from file\n",
        "        # Creates blueish file\n",
        "        im = PIL.Image.open('dataset/Bean/{}'.format(dir_contents_Bean[count]))\n",
        "        print('dataset/Bean/{}'.format(dir_contents_Bean[count]))\n",
        "        # Creates images with normal color\n",
        "        #im = cv2.imread('dataset/Bean/{}.jpg'.format(dir_contents_Bean[count]))\n",
        "        im = np.array(im)\n",
        "        print(im.shape)\n",
        "        \n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) \n",
        "\n",
        "        face_resize = cv2.resize(gray, (width, height))\n",
        "        print(face_resize.shape)\n",
        "\n",
        "        cv2.imwrite('% s/% s.png' % (path_gray_Bean, 'photoBean{}'.format(count)), face_resize) \n",
        "        #cv2.waitKey()\n",
        "\n",
        "        count += 1\n",
        "\n",
        "# Call this function whenever you need to create a dataset of the person's images\n",
        "create_dataset_Bean()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "dataset/Bean/016.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/020.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/015.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/017.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/007.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/012.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/003.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/006.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/008.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/019.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/013.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/018.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/010.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/002.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/011.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/009.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/004.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/001.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/014.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/005.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xy18XBb6Xak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6953a381-5576-464a-9fa2-1709b00be795"
      },
      "source": [
        "\n",
        "path_gray_Kim = 'dataset_gray/{}'.format('Kim')\n",
        "\n",
        "# Add a verfication for this step\n",
        "if not os.path.exists(path_gray_Kim):\n",
        "    os.mkdir(path_gray_Kim) \n",
        "\n",
        "sub_data = 'Kim'\n",
        "dir_contents_Kim = os.listdir('dataset/Kim')\n",
        "print(len(dir_contents_Kim))\n",
        "\n",
        "def create_dataset_Kim():  \n",
        "    # Image to be resized to this shape\n",
        "    (width, height) = (180, 200)      \n",
        "\n",
        "    # The program loops until it has 20 images of the face. \n",
        "    count = 0\n",
        "    while count < 20:\n",
        "        # Read from file\n",
        "        im = PIL.Image.open('dataset/Kim/{}'.format(dir_contents_Kim[count]))\n",
        "        print('dataset/Bean/{}'.format(dir_contents_Kim[count]))\n",
        "        im = np.array(im)\n",
        "        print(im.shape)\n",
        "        \n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) \n",
        "\n",
        "        face_resize = cv2.resize(gray, (width, height))\n",
        "        print(face_resize.shape)\n",
        "\n",
        "        cv2.imwrite('% s/% s.png' % (path_gray_Kim, 'photoKim{}'.format(count)), face_resize) \n",
        "\n",
        "        count += 1\n",
        "\n",
        "# Call this function whenever you need to create a dataset of the person's images\n",
        "create_dataset_Kim()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "dataset/Bean/016.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/020.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/015.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/027.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/017.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/007.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/012.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/003.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/021.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/006.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/008.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/018.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/023.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/002.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/011.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/009.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/004.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/001.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/014.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/005.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMgWHwkxZYJD",
        "colab_type": "text"
      },
      "source": [
        "## Import Keras layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vZDgJG5aTft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "52c83a89-272f-4b9e-f8c2-ddfac8847d15"
      },
      "source": [
        "from tensorflow.keras import backend as K, models\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import os\n",
        "from os.path import join as join_\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX86zVXobE0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "87cf12a6-6f87-41b8-bafc-5a4ea458ce52"
      },
      "source": [
        "# Setting up the dataset\n",
        "\n",
        "SET_DIR = 'dataset_gray/'\n",
        "NUM_CLASSES = len(os.listdir('dataset_gray'))\n",
        "print(NUM_CLASSES)\n",
        "\n",
        "# The shape which VGG19 accepts as input and thus each image is resized to\n",
        "image_shape = (224, 224, 3)\n",
        "\n",
        "# NUM_EXAMPLES is the number of (A,P,N) triplets chosen for the same class (N belongs to a different class of course)\n",
        "NUM_EXAMPLES = 15\n",
        "\n",
        "# Triplets list will contain anchor(A), positive(P) and negative(N) triplets.\n",
        "triplets = []\n",
        "A = P = N = []\n",
        "A_str = P_str = N_str = []\n",
        "\n",
        "# creating anchor, positive, negative triplets\n",
        "for _ in range(NUM_EXAMPLES):\n",
        "    for direc in os.listdir(SET_DIR):\n",
        "        dir_path = SET_DIR + direc\n",
        "        dir_contents = os.listdir(dir_path)\n",
        "        length = len(dir_contents)\n",
        "        print(length)\n",
        "        \n",
        "        A_ran = dir_contents[np.random.randint(0, length)]\n",
        "        A_str = Image.open(join_(dir_path, A_ran))\n",
        "        anchor = np.asarray(A_str)/255\n",
        "        # anchor.shape = (200, 180, 3)        \n",
        "        # Padding with zeros for each channel in RGB\n",
        "        anchor = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in anchor.T]).T\n",
        "        \n",
        "        P_ran = dir_contents[np.random.randint(0, length)]\n",
        "        P_str = Image.open(join_(dir_path, P_ran))\n",
        "        positive = np.asarray(P_str)/255\n",
        "        positive = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in positive.T]).T\n",
        "        \n",
        "        neg_dir = os.listdir(SET_DIR)[np.random.randint(NUM_CLASSES)]\n",
        "        while neg_dir == direc: \n",
        "            neg_dir = os.listdir(SET_DIR)[np.random.randint(NUM_CLASSES)]\n",
        "            \n",
        "        length_negative = len(os.listdir(SET_DIR + neg_dir))\n",
        "\n",
        "        N_ran = os.listdir(SET_DIR + neg_dir)[np.random.randint(0, length_negative)]\n",
        "        N_str = Image.open(join_(SET_DIR + neg_dir, N_ran))\n",
        "        negative = np.asarray(N_str)/255\n",
        "        \n",
        "        negative = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in negative.T]).T\n",
        "        \n",
        "        # append triplet\n",
        "        triplets.append([anchor, positive, negative])\n",
        "        A.append(anchor)\n",
        "        P.append(positive)\n",
        "        N.append(negative)\n",
        "\n",
        "        #triplets.append([A_ran, P_ran, N_ran])\n",
        "        #A.append(A_ran)\n",
        "        #P.append(P_ran)\n",
        "        #N.append(N_ran)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gLDfB2Wlbh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "36fe3f20-c6cf-4331-ca9a-75d58c177644"
      },
      "source": [
        "print(triplets[1:3])\n",
        "#print(A[0])\n",
        "#print(P)\n",
        "#print(N)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gZ-LvbNljII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_function(vects, alpha=0.2):\n",
        "    x, y, z = vects\n",
        "    sum_square_xy = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    sum_square_xz = K.sum(K.square(x - z), axis=1, keepdims=True)\n",
        "    return K.sum(K.maximum(sum_square_xy - sum_square_xz + alpha, 0), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJS4OFyCEq8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Using the VGG16 model defined in keras.applications\n",
        "\n",
        "def VGG():\n",
        "    image_input = Input(shape=(224, 224, 3))\n",
        "    model = VGG16(input_tensor=image_input, weights='imagenet', include_top=True)\n",
        "    model.layers[-1].activation = relu\n",
        "    x_out = Dense(64)(model.layers[-1].output)\n",
        "    \n",
        "    new_model = Model(inputs=image_input, outputs=x_out)\n",
        "    return new_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiE6cHhAFANN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    anchor = Input(shape=image_shape, name='anchor')\n",
        "    positive = Input(shape=image_shape, name='positive')\n",
        "    negative = Input(shape=image_shape, name='negative')\n",
        "    \n",
        "    # Passing each image through the VGG model\n",
        "    req_model = VGG()\n",
        "    \n",
        "    # Pass the images through the same model\n",
        "    anchor_encoding = req_model(anchor)\n",
        "    positive_encoding = req_model(positive)\n",
        "    negative_encoding = req_model(negative)\n",
        "\n",
        "    # Incorporating the triplet loss in the SimVecLayer\n",
        "    SimVecLayer = Lambda(triplet_function, output_shape=(1,))\n",
        "    \n",
        "    sim_APN = SimVecLayer([anchor_encoding, positive_encoding, negative_encoding])\n",
        "    \n",
        "    return Model(inputs=[anchor, positive, negative], outputs=sim_APN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTqbHGDDFHb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "ffb65e6c-88f0-4fdb-f2af-8c42fcfd2f37"
      },
      "source": [
        "model = get_model()\n",
        "\n",
        "# Compile the model with a loss and optimizer\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae']) \n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 7s 0us/step\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "anchor (InputLayer)             [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "positive (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "negative (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model (Model)                   (None, 64)           138421608   anchor[0][0]                     \n",
            "                                                                 positive[0][0]                   \n",
            "                                                                 negative[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (1,)                 0           model[1][0]                      \n",
            "                                                                 model[2][0]                      \n",
            "                                                                 model[3][0]                      \n",
            "==================================================================================================\n",
            "Total params: 138,421,608\n",
            "Trainable params: 138,421,608\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e34HubeOFgCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "5f95564f-8a79-4ca5-ca72-2dc46dca539a"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2cabf02ce23a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mnode_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_ib-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0minbound_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                     \u001b[0minbound_layer_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'InputLayer' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwnxrTNZF2w5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "66d645cb-bdb3-4cb4-fc1d-75aea5255a9e"
      },
      "source": [
        "# Train the model (done over the intel cloud) \n",
        "A, P, N = np.array(A), np.array(P), np.array(N)\n",
        "\n",
        "model.fit(x = [A, P, N], y = np.zeros((A.shape[0],1)),\n",
        "                  epochs=100, verbose=1,\n",
        "                  batch_size=32, validation_split=0.3,\n",
        "                  callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 18s 6s/step - loss: 39.3770 - mae: 6.2667 - val_loss: 32.6800 - val_mae: 4.1000\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 39.3770 - mae: 6.2667 - val_loss: 32.6800 - val_mae: 4.1000\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 39.3770 - mae: 6.2667 - val_loss: 32.6800 - val_mae: 4.1000\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 39.3770 - mae: 6.2667 - val_loss: 32.6800 - val_mae: 4.1000\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 39.3770 - mae: 6.2667 - val_loss: 32.6800 - val_mae: 4.1000\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 39.3770 - mae: 6.2667 - val_loss: 32.6800 - val_mae: 4.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe32cf17dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhL7EB7YGGqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p saved_model\n",
        "new_model = model\n",
        "new_model.save('saved_model/my_model') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqReCSRwGMux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(new_model.get_input_shape_at(0))\n",
        "print(new_model)\n",
        "for node in model.outputs:\n",
        "  print(node)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYRaEychGO3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tflite_model = tf.keras.models.load_model('saved_model/my_model')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(tflite_model)\n",
        "tflite_save = converter.convert()\n",
        "open(\"greek_smart_reply_model.tflite\", \"wb\").write(tflite_save)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl_CUwy7GTv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter = tf.lite.Interpreter('greek_smart_reply_model.tflite')\n",
        "#interpreter.allocate_tensors()\n",
        "\n",
        "#input_details = interpreter.get_input_details()\n",
        "print(interpreter.get_output_details())\n",
        "interpreter.get_tensor_details()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}