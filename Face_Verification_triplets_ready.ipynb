{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Verification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smgTeuy3iW3D",
        "colab_type": "text"
      },
      "source": [
        "## Notebook for face verification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqynvVKKhQeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GGMHNAkivPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f9c0257a-4af8-4e18-825c-6541b66bbf7b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as K\n",
        "import os\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "print(tf.__version__)\n",
        "print(K.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipFXBapciWZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Connect with drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNcQ-Q2Likkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read data from drive\n",
        "with open('drive/My Drive/Face Verification/haarcascade_frontalface_default.xml', 'r') as f:\n",
        "    haar_file = f.read()\n",
        "\n",
        "print(haar_file)\n",
        "#with open('drive/My Drive/Smart Reply/10000_labels.csv', 'r') as f:\n",
        "    #labels = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZGxznt9oR6P",
        "colab_type": "text"
      },
      "source": [
        "# Take 20 photos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oK-3Cf_no8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5ecbd495-6721-4b9d-9307-46d2224b752e"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "# All the faces data will be present this folder \n",
        "dataset = './dataset'\n",
        "\n",
        "if not os.path.exists(dataset):\n",
        "    os.mkdir(dataset)\n",
        "sub_data = input(\"Enter your username: \")\n",
        "#sub_data_gray = input(\"Enter your username for gray scale: \")\n",
        "\n",
        "# Use the username as path name\n",
        "path = os.path.join(dataset, sub_data) \n",
        "path_gray = 'dataset/{}{}'.format(sub_data,'_gray')\n",
        "\n",
        "# Add a verfication for this step\n",
        "if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "    os.mkdir(path_gray)    \n",
        "\n",
        "def take_photo(filename='dataset/name/photo.jpg', quality=1):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your username: george\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19cfCmUqno7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "ed24ead9-c7aa-41db-eafb-bfccde7bf50f"
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# Take 20 photos\n",
        "for i in range(20):\n",
        "  try:\n",
        "    filename = take_photo(filename='dataset/{}/photo{}.jpg'.format(sub_data,i))\n",
        "    print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "    #display(Image(filename))\n",
        "  except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "    print(str(err))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo0.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo1.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo2.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo3.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo4.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo5.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo6.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo7.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo8.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo9.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo10.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo11.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo12.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo13.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo14.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo15.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo16.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo17.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo18.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved to dataset/george/photo19.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKN_wBnTWRx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# zip saved model folder\n",
        "!zip -r /content/dataset/george.zip /content/dataset/george"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KshBKGWFYo4U",
        "colab_type": "text"
      },
      "source": [
        "## If you come later unzip the file with photos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQT-J7X-Ysb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('dataset'):\n",
        "    os.mkdir('dataset')\n",
        "\n",
        "if not os.path.exists('dataset_gray'):\n",
        "    os.mkdir('dataset_gray')\n",
        "\n",
        "!unzip george.zip -d dataset\n",
        "!unzip Kim.zip -d dataset\n",
        "!unzip Bean.zip -d dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8QnMJVjjfp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "path_gray_george = 'dataset_gray/{}'.format('george')\n",
        "\n",
        "# Add a verfication for this step\n",
        "if not os.path.exists(path_gray_george):\n",
        "    os.mkdir(path_gray_george) \n",
        "\n",
        "sub_data = 'george'\n",
        "\n",
        "def create_dataset_george():\n",
        "    # The file containing the pretrained classifier \n",
        "    haar_file = 'drive/My Drive/Face Verification/haarcascade_frontalface_default.xml'\n",
        "        \n",
        "    # Image to be resized to this shape\n",
        "    (width, height) = (180, 200)     \n",
        "    \n",
        "    # Make the cascade classifier object\n",
        "    face_cascade = cv2.CascadeClassifier(haar_file) \n",
        "    #webcam = cv2.VideoCapture(0)  \n",
        "\n",
        "    # The program loops until it has 20 images of the face. \n",
        "    count = 0\n",
        "    while count < 20:\n",
        "        # Read from file\n",
        "        # Creates blueish file\n",
        "        im = PIL.Image.open('dataset/{}/photo{}.jpg'.format(sub_data,count))\n",
        "        # Creates images with normal color\n",
        "        #im = cv2.imread('dataset/{}/photo{}.jpg'.format(sub_data,count))\n",
        "        im = np.array(im)\n",
        "        #print(im.shape)\n",
        "        \n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) \n",
        "        # Detect the face\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 4) \n",
        "        \n",
        "        face_resize = None\n",
        "        for (x, y, w, h) in faces:\n",
        "            # The classifier seemed to scrap the chin and hair. Adjustments made to accomodate those.\n",
        "            face = im[y-60 : y+h+60, x-20 : x+w+20] \n",
        "            face_resize = cv2.resize(face, (width, height)) \n",
        "            cv2.imwrite('% s/% s.png' % (path_gray_george, 'photoGeorge{}'.format(count)), face_resize) \n",
        "        count += 1\n",
        "\n",
        "        #cv2.imshow('OpenCV', im) \n",
        "        #key = cv2.waitKey(100) \n",
        "        #if key == 27: \n",
        "            #break\n",
        "\n",
        "# Call this function whenever you need to create a dataset of the person's images\n",
        "create_dataset_george()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ez0dU9Lr1kf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a12792d-74d7-41b4-b902-c3dcc4589c91"
      },
      "source": [
        "\n",
        "path_gray_Bean = 'dataset_gray/{}'.format('Bean')\n",
        "\n",
        "# Add a verfication for this step\n",
        "if not os.path.exists(path_gray_Bean):\n",
        "    os.mkdir(path_gray_Bean) \n",
        "\n",
        "sub_data = 'Bean'\n",
        "dir_contents_Bean = os.listdir('dataset/Bean')\n",
        "print(len(dir_contents_Bean))\n",
        "\n",
        "def create_dataset_Bean():\n",
        "   \n",
        "    # Image to be resized to this shape\n",
        "    (width, height) = (180, 200) \n",
        "\n",
        "    # The program loops until it has 20 images of the face. \n",
        "    count = 0\n",
        "    while count < 20:\n",
        "        # Read from file\n",
        "        # Creates blueish file\n",
        "        im = PIL.Image.open('dataset/Bean/{}'.format(dir_contents_Bean[count]))\n",
        "        print('dataset/Bean/{}'.format(dir_contents_Bean[count]))\n",
        "        # Creates images with normal color\n",
        "        #im = cv2.imread('dataset/Bean/{}.jpg'.format(dir_contents_Bean[count]))\n",
        "        im = np.array(im)\n",
        "        print(im.shape)\n",
        "        \n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) \n",
        "\n",
        "        face_resize = cv2.resize(gray, (width, height))\n",
        "        print(face_resize.shape)\n",
        "\n",
        "        cv2.imwrite('% s/% s.png' % (path_gray_Bean, 'photoBean{}'.format(count)), face_resize) \n",
        "        #cv2.waitKey()\n",
        "\n",
        "        count += 1\n",
        "\n",
        "# Call this function whenever you need to create a dataset of the person's images\n",
        "create_dataset_Bean()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "dataset/Bean/014.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/009.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/003.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/002.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/013.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/012.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/006.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/016.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/005.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/011.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/008.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/018.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/020.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/004.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/001.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/015.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/007.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/019.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/017.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/010.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xy18XBb6Xak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba695d79-df35-4f40-d748-e3fde3bbe0da"
      },
      "source": [
        "\n",
        "path_gray_Kim = 'dataset_gray/{}'.format('Kim')\n",
        "\n",
        "# Add a verfication for this step\n",
        "if not os.path.exists(path_gray_Kim):\n",
        "    os.mkdir(path_gray_Kim) \n",
        "\n",
        "sub_data = 'Kim'\n",
        "dir_contents_Kim = os.listdir('dataset/Kim')\n",
        "print(len(dir_contents_Kim))\n",
        "\n",
        "def create_dataset_Kim():  \n",
        "    # Image to be resized to this shape\n",
        "    (width, height) = (180, 200)      \n",
        "\n",
        "    # The program loops until it has 20 images of the face. \n",
        "    count = 0\n",
        "    while count < 20:\n",
        "        # Read from file\n",
        "        im = PIL.Image.open('dataset/Kim/{}'.format(dir_contents_Kim[count]))\n",
        "        print('dataset/Bean/{}'.format(dir_contents_Kim[count]))\n",
        "        im = np.array(im)\n",
        "        print(im.shape)\n",
        "        \n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) \n",
        "\n",
        "        face_resize = cv2.resize(gray, (width, height))\n",
        "        print(face_resize.shape)\n",
        "\n",
        "        cv2.imwrite('% s/% s.png' % (path_gray_Kim, 'photoKim{}'.format(count)), face_resize) \n",
        "\n",
        "        count += 1\n",
        "\n",
        "# Call this function whenever you need to create a dataset of the person's images\n",
        "create_dataset_Kim()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "dataset/Bean/014.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/009.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/023.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/003.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/002.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/012.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/006.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/016.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/027.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/005.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/011.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/008.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/018.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/020.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/004.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/001.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/021.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/015.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/007.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n",
            "dataset/Bean/017.jpg\n",
            "(256, 256, 3)\n",
            "(200, 180, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMgWHwkxZYJD",
        "colab_type": "text"
      },
      "source": [
        "## Import Keras layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vZDgJG5aTft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cc01f8d7-4838-4e55-b07a-8c74aa45b18e"
      },
      "source": [
        "from tensorflow.keras import backend as K, models\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.activations import relu\n",
        "import os\n",
        "from os.path import join as join_\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX86zVXobE0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "e3df839f-23d3-4555-b075-aa1189d29cdd"
      },
      "source": [
        "# Setting up the dataset\n",
        "\n",
        "SET_DIR = 'dataset_gray/'\n",
        "NUM_CLASSES = len(os.listdir('dataset_gray'))\n",
        "print(NUM_CLASSES)\n",
        "\n",
        "# The shape which VGG19 accepts as input and thus each image is resized to\n",
        "image_shape = (224, 224, 3)\n",
        "\n",
        "# NUM_EXAMPLES is the number of (A,P,N) triplets chosen for the same class (N belongs to a different class of course)\n",
        "NUM_EXAMPLES = 15\n",
        "\n",
        "# Triplets list will contain anchor(A), positive(P) and negative(N) triplets.\n",
        "triplets = []\n",
        "A = P = N = []\n",
        "A_str = P_str = N_str = []\n",
        "\n",
        "# creating anchor, positive, negative triplets\n",
        "for _ in range(NUM_EXAMPLES):\n",
        "    for direc in os.listdir(SET_DIR):\n",
        "        dir_path = SET_DIR + direc\n",
        "        dir_contents = os.listdir(dir_path)\n",
        "        length = len(dir_contents)\n",
        "        print(length)\n",
        "        \n",
        "        A_ran = dir_contents[np.random.randint(0, length)]\n",
        "        A_str = Image.open(join_(dir_path, A_ran))\n",
        "        anchor = np.asarray(A_str)/255\n",
        "        # anchor.shape = (200, 180, 3)        \n",
        "        # Padding with zeros for each channel in RGB\n",
        "        anchor = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in anchor.T]).T\n",
        "        \n",
        "        P_ran = dir_contents[np.random.randint(0, length)]\n",
        "        P_str = Image.open(join_(dir_path, P_ran))\n",
        "        positive = np.asarray(P_str)/255\n",
        "        positive = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in positive.T]).T\n",
        "        \n",
        "        neg_dir = os.listdir(SET_DIR)[np.random.randint(NUM_CLASSES)]\n",
        "        while neg_dir == direc: \n",
        "            neg_dir = os.listdir(SET_DIR)[np.random.randint(NUM_CLASSES)]\n",
        "            \n",
        "        length_negative = len(os.listdir(SET_DIR + neg_dir))\n",
        "\n",
        "        N_ran = os.listdir(SET_DIR + neg_dir)[np.random.randint(0, length_negative)]\n",
        "        N_str = Image.open(join_(SET_DIR + neg_dir, N_ran))\n",
        "        negative = np.asarray(N_str)/255\n",
        "        \n",
        "        negative = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in negative.T]).T\n",
        "        \n",
        "        # append triplet\n",
        "        #triplets.append([anchor, positive, negative])\n",
        "        #A.append(anchor)\n",
        "        #P.append(positive)\n",
        "        #N.append(negative)\n",
        "\n",
        "        triplets.append([A_ran, P_ran, N_ran])\n",
        "        A.append(A_ran)\n",
        "        P.append(P_ran)\n",
        "        N.append(N_ran)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gLDfB2Wlbh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f0f20d97-2684-470a-92a0-696d22bd5c05"
      },
      "source": [
        "print(triplets[1:100])\n",
        "#print(A[0])\n",
        "#print(P)\n",
        "#print(N)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['photoKim10.png', 'photoKim7.png', 'photoBean4.png'], ['photoGeorge9.png', 'photoGeorge3.png', 'photoBean3.png'], ['photoBean13.png', 'photoBean15.png', 'photoGeorge10.png'], ['photoKim1.png', 'photoKim11.png', 'photoGeorge0.png'], ['photoGeorge2.png', 'photoGeorge4.png', 'photoBean12.png'], ['photoBean17.png', 'photoBean12.png', 'photoGeorge6.png'], ['photoKim3.png', 'photoKim15.png', 'photoBean1.png'], ['photoGeorge16.png', 'photoGeorge16.png', 'photoBean11.png'], ['photoBean5.png', 'photoBean11.png', 'photoKim8.png'], ['photoKim11.png', 'photoKim0.png', 'photoBean3.png'], ['photoGeorge19.png', 'photoGeorge9.png', 'photoBean4.png'], ['photoBean14.png', 'photoBean11.png', 'photoGeorge2.png'], ['photoKim11.png', 'photoKim2.png', 'photoGeorge6.png'], ['photoGeorge13.png', 'photoGeorge19.png', 'photoKim15.png'], ['photoBean8.png', 'photoBean2.png', 'photoKim8.png'], ['photoKim4.png', 'photoKim11.png', 'photoGeorge4.png'], ['photoGeorge6.png', 'photoGeorge7.png', 'photoBean2.png'], ['photoBean7.png', 'photoBean13.png', 'photoGeorge0.png'], ['photoKim14.png', 'photoKim12.png', 'photoBean14.png'], ['photoGeorge6.png', 'photoGeorge12.png', 'photoKim16.png'], ['photoBean1.png', 'photoBean10.png', 'photoGeorge17.png'], ['photoKim17.png', 'photoKim2.png', 'photoGeorge12.png'], ['photoGeorge3.png', 'photoGeorge4.png', 'photoBean16.png'], ['photoBean11.png', 'photoBean3.png', 'photoGeorge1.png'], ['photoKim18.png', 'photoKim6.png', 'photoBean8.png'], ['photoGeorge9.png', 'photoGeorge2.png', 'photoKim5.png'], ['photoBean4.png', 'photoBean10.png', 'photoGeorge19.png'], ['photoKim7.png', 'photoKim14.png', 'photoGeorge9.png'], ['photoGeorge1.png', 'photoGeorge3.png', 'photoBean2.png'], ['photoBean3.png', 'photoBean13.png', 'photoKim4.png'], ['photoKim0.png', 'photoKim2.png', 'photoBean10.png'], ['photoGeorge7.png', 'photoGeorge10.png', 'photoKim17.png'], ['photoBean3.png', 'photoBean8.png', 'photoKim9.png'], ['photoKim2.png', 'photoKim9.png', 'photoBean6.png'], ['photoGeorge3.png', 'photoGeorge15.png', 'photoBean15.png'], ['photoBean11.png', 'photoBean4.png', 'photoKim10.png'], ['photoKim0.png', 'photoKim0.png', 'photoBean13.png'], ['photoGeorge9.png', 'photoGeorge13.png', 'photoBean17.png'], ['photoBean6.png', 'photoBean18.png', 'photoKim5.png'], ['photoKim12.png', 'photoKim3.png', 'photoGeorge17.png'], ['photoGeorge12.png', 'photoGeorge17.png', 'photoBean17.png'], ['photoBean6.png', 'photoBean15.png', 'photoGeorge3.png'], ['photoKim10.png', 'photoKim10.png', 'photoBean3.png'], ['photoGeorge16.png', 'photoGeorge9.png', 'photoBean12.png']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gZ-LvbNljII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}